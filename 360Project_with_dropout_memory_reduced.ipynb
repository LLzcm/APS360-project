{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5OaH7rNT8V4",
        "outputId": "38cc6ed4-43bd-441f-ee6b-832245457560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f224b085db0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch.nn as nn\n",
        "drive.mount('/content/gdrive')\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ysSVJAEd1mM"
      },
      "outputs": [],
      "source": [
        "\n",
        "path = \"/content/gdrive/MyDrive/APS360/360Project/final_dataset\"\n",
        "train_dir = os.path.join(path, 'train/')\n",
        "val_dir = os.path.join(path, 'val/')\n",
        "#test_dir = '/content/gdrive/MyDrive/APS360/360Project/maxres_thumbnails/test'\n",
        "classes =['Autos & Vehicles','Food & Drink','Pets & Animals','Science & Education','Sports']\n",
        "data_transform = transforms.Compose([transforms.RandomResizedCrop(224),transforms.ToTensor()])\n",
        "train_set = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "validation_set = datasets.ImageFolder(val_dir, transform=data_transform)\n",
        "#test_set = datasets.ImageFolder(test_dir, transform=data_transform)\n",
        "#Make a quick and small dataset\n",
        "train_set,other_dataset = random_split(dataset=train_set,lengths=[3000,3000])\n",
        "validation_set,test_set = random_split(dataset=validation_set,lengths=[750,750]) #This is half of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIe_Mr4KU7oY"
      },
      "outputs": [],
      "source": [
        "#Take in data\n",
        "# Train : Validation : Test = 2:1:1\n",
        "#path = \"/content/gdrive/MyDrive/APS360/360Project/small_test\"\n",
        "#file_name = os.listdir(path)\n",
        "#count_pic = 0\n",
        "#for files in file_name:\n",
        "#  count_pic+=len(os.listdir(path+\"/\"+files))\n",
        "#train_index = count_pic//2\n",
        "#validation_index = count_pic//4\n",
        "#test_index = count_pic - train_index - validation_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80rSrWf7VSVp"
      },
      "outputs": [],
      "source": [
        "#data_dir = \"/content/gdrive/MyDrive/APS360/360Project/small_test\"\n",
        "#classes = ['Arts _ Entertainment','Autos _ Vehicles','Beauty _ Fitness','Food _ Drink','Games','Sports']\n",
        "#data_transform = transforms.Compose([transforms.RandomResizedCrop(224),transforms.ToTensor()])\n",
        "#total_data = datasets.ImageFolder(data_dir, transform=data_transform)\n",
        "#train_set,other_dataset = random_split(dataset=total_data,lengths=[train_index,count_pic-train_index])\n",
        "#validation_set,test_set = random_split(dataset=other_dataset,lengths=[validation_index,test_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln01Oe6JX5A1",
        "outputId": "7da193e2-4eea-40f3-b32a-8c7c03a0b12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training images:  3000\n",
            "Num validation images:  750\n"
          ]
        }
      ],
      "source": [
        "print('Num training images: ', len(train_set))\n",
        "print('Num validation images: ', len(validation_set))\n",
        "#print('Num test images: ', len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lh99jyVYB7e"
      },
      "outputs": [],
      "source": [
        "# define dataloader parameters\n",
        "batch_size  = 192\n",
        "num_workers = 0\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmPsmi-WFh7b"
      },
      "outputs": [],
      "source": [
        "#!pip install numba\n",
        "\n",
        "#from numba import cuda \n",
        "#device = cuda.get_current_device()\n",
        "#device.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aaf6r1gRV_o2"
      },
      "outputs": [],
      "source": [
        "#Model CNN \n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class LargeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LargeNet, self).__init__()\n",
        "        self.name = \"large\"\n",
        "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(5, 10, 5)\n",
        "        self.conv3 = nn.Conv2d(10, 20, 4)\n",
        "        self.conv4 = nn.Conv2d(20, 40, 4)\n",
        "        self.fc1 = nn.Linear(4840, 320)\n",
        "        self.fc2 = nn.Linear(320, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = x.view(-1, 4840)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eH8NJGFWXfE"
      },
      "outputs": [],
      "source": [
        "#Model Transferlearning+ANN Classifier\n",
        "# Alexnet\n",
        "\n",
        "import torchvision.models\n",
        "alexNet = torchvision.models.alexnet(pretrained=True)\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "features = alexNet.features(images)\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g6ixuR_eewI"
      },
      "outputs": [],
      "source": [
        "# VGGnet\n",
        "vggNet = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "features = vggNet.features(images)\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ajdnGpViWnt"
      },
      "outputs": [],
      "source": [
        "# ResNet\n",
        "#resNet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "resNet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "features = resNet(images)\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_a27FRfp5sc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "602dc6ced75a4686ac7849573a4a8fcd",
            "aa87a47a5cd341118444f2a1380f7676",
            "75d2dd2837c34826abc80572c38cff63",
            "a376ca07094444b3ac578a6253851a86",
            "2e659682ce6f4026966b9aee69a64082",
            "5e383afb7ccd41f5a4ec73c07c58ea26",
            "3a2a11ec50bb4dcc99d7a5cdc282f471",
            "7e01efbdcedc4479a3df867dcfef78d6",
            "cc2fe823a44d49058cfac8c29626c818",
            "68f4ee30ac5a424ebfe42f97043ddad6",
            "e0589a10729f4288a539140deb9c0011"
          ]
        },
        "outputId": "c4ade7a9-6eb0-4f21-e938-aa8b3742b1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/49.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "602dc6ced75a4686ac7849573a4a8fcd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#GoogleENET\n",
        "googleNet = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
        "#dataiter = iter(train_loader)\n",
        "#images, labels = dataiter.next()\n",
        "#features = googleNet(images)\n",
        "#features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW9Dwqpk6ytP"
      },
      "outputs": [],
      "source": [
        "#EfficientNet\n",
        "!pip install --upgrade efficientnet-pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "effNet = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "features = effNet(images)\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Okq-8eDuDcny"
      },
      "outputs": [],
      "source": [
        "#Xeception\n",
        "!pip install timm\n",
        "import timm\n",
        "xcep = timm.create_model('xception', pretrained=True)\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "features = xcep(images)\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0QetsGfZP5s"
      },
      "outputs": [],
      "source": [
        "#Artifical Neural Network Architecture (alexNet)\n",
        "ALNC = alexNet.features\n",
        "\n",
        "class ANNClassifier_ALNC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_ALNC, self).__init__()\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 10)\n",
        "        self.fc2 = nn.Linear(10, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 256 * 6 * 6) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7rdZQeOe4ce"
      },
      "outputs": [],
      "source": [
        "#Artifical Neural Network Architecture (vggNet)\n",
        "VGG = vggNet.features\n",
        "class ANNClassifier_VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_VGG, self).__init__()\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 10)\n",
        "        self.fc2 = nn.Linear(10, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 512 * 7 * 7) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF4VNPaSi9rm"
      },
      "outputs": [],
      "source": [
        "#Artifical Neural Network Architecture (resNet)\n",
        "RES = resNet\n",
        "class ANNClassifier_RES(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_RES, self).__init__()\n",
        "        self.fc1 = nn.Linear(1000, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc3 = nn.Linear(10, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1000) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoN5bvmuqVNc"
      },
      "outputs": [],
      "source": [
        "#Artifical Neural Network Architecture (GoogleNet)\n",
        "Google = googleNet\n",
        "class ANNClassifier_GOOGLE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_GOOGLE, self).__init__()\n",
        "        self.fc1 = nn.Sequential(nn.Dropout(0.5),nn.Linear(1000,6))\n",
        "        #self.fc2 = nn.Linear(10, 6)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1000) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi6O2Emn8Hc1"
      },
      "outputs": [],
      "source": [
        "#Artifical Neural Network Architecture (EfficientNet)\n",
        "EFF = effNet\n",
        "class ANNClassifier_EFF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_EFF, self).__init__()\n",
        "        self.fc1 = nn.Linear(1000, 10)\n",
        "        self.fc2 = nn.Linear(10, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1000) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHbjtrq7Eflo"
      },
      "outputs": [],
      "source": [
        "#Artifical Neural Network Architecture (Exception)\n",
        "EXP = xcep\n",
        "class ANNClassifier_EXP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier_EXP, self).__init__()\n",
        "        self.fc1 = nn.Linear(1000, 10)\n",
        "        self.fc2 = nn.Linear(10, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1000) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X801oYTZhXi"
      },
      "source": [
        "Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOm1VXF-ZfKP"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, train=False):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      if train:\n",
        "          data_loader = train_loader\n",
        "      else:\n",
        "          data_loader = val_loader\n",
        "\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for imgs, labels in data_loader:\n",
        "        \n",
        "         \n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        #############################################\n",
        "        #改这里 change here to switch model\n",
        "        output = model(Google(imgs))\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXdCkWkda9gk"
      },
      "source": [
        "Train code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm_XPXy6ZkdJ"
      },
      "outputs": [],
      "source": [
        "def train(model, data, lr,batch_size=20, num_epochs=1,train_loader=train_loader):\n",
        "    #train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           #num_workers=num_workers, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    start_time=time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        mini_b=0\n",
        "        mini_batch_correct = 0\n",
        "        Mini_batch_total = 0\n",
        "        for imgs, labels in iter(train_loader):\n",
        "          \n",
        "            \n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            #############################################\n",
        "\n",
        "          #### ALNC is alexNet.features (AlexNet without classifier) ####\n",
        "          #### VGG is vggNet.fearures (VggNet without classifier) ####\n",
        "          #### RES is resNet\n",
        "          #改这里 change here to switch model\n",
        "            out = model(Google(imgs))             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "\n",
        "\n",
        "            ##### Mini_batch Accuracy ##### We don't compute accuracy on the whole training set in every iteration!\n",
        "            pred = out.max(1, keepdim=True)[1]\n",
        "            mini_batch_correct = pred.eq(labels.view_as(pred)).sum().item()\n",
        "            Mini_batch_total = imgs.shape[0]\n",
        "            train_acc.append((mini_batch_correct / Mini_batch_total))\n",
        "           ###########################\n",
        "\n",
        "          # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy\n",
        "            n += 1\n",
        "            mini_b += 1\n",
        "            print(\"Iteration: \",n,'Progress: % 6.2f ' % ((epoch * len(train_loader) + mini_b) / (num_epochs * len(train_loader))*100),'%', \"Time Elapsed: % 6.2f s \" % (time.time()-start_time))\n",
        "\n",
        "\n",
        "        print (\"Epoch %d Finished. \" % epoch ,\"Time per Epoch: % 6.2f s \"% ((time.time()-start_time) / (epoch +1)))\n",
        "\n",
        "\n",
        "    end_time= time.time()\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Training\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")    \n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Validation Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    train_acc.append(get_accuracy(model, train=True))\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "    print (\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % ( (end_time-start_time), ((end_time-start_time) / num_epochs) ))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3QzXDOgDYcz"
      },
      "outputs": [],
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"/content/gdrive/MyDrive/APS360/360Project/Models/model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEX9DBDdbDWZ"
      },
      "outputs": [],
      "source": [
        "use_cuda = True\n",
        "#model = ANNClassifier_ALNC()\n",
        "#model = ANNClassifier_VGG()\n",
        "#model = ANNClassifier_EFF()\n",
        "#model = ANNClassifier_EXP()\n",
        "model = ANNClassifier_GOOGLE()\n",
        "#model = ANNClassifier_RES()\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  #ALNC.cuda()\n",
        "  #VGG.cuda()\n",
        "  #RES.cuda()\n",
        "  model.cuda()\n",
        "  Google.cuda()\n",
        "  #EFF.cuda()\n",
        "  #EXP.cuda()\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "  \n",
        "#proper model\n",
        "train(model, [],lr=0.001, batch_size=batch_size, num_epochs=10, train_loader=train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYuYWB1EDbPc"
      },
      "outputs": [],
      "source": [
        "model_path = get_model_name(\"google_drop_out\", batch_size=128, learning_rate=0.001, epoch=10)\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZRROl9D2VF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YB7TEHa2yYA"
      },
      "outputs": [],
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=5,num_workers=num_workers, shuffle=True)\n",
        "\n",
        "def get_test_accuracy(model):\n",
        "    data_loader = test_loader\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predict=[]\n",
        "    truth=[]\n",
        "    for imgs, labels in data_loader:\n",
        "        \n",
        "         \n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        #if torch.cuda.is_available():\n",
        "        #  imgs = imgs.cuda()\n",
        "        #  labels = labels.cuda()\n",
        "        #############################################\n",
        "        #改这里 change here to switch model\n",
        "        output = model(Google(imgs))\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        predict.append(pred)\n",
        "        truth.append(labels)\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    #return predict,truth\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANNClassifier_GOOGLE()\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/APS360/360Project/Models/model_google_drop_out_bs128_lr0.001_epoch10',map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boI9q74DzOZ0",
        "outputId": "1de9de6c-a1bb-411c-837f-4428980c7d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhVwIhWl4gC9",
        "outputId": "a969f862-69f6-427e-ba70-779ddb16e4e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.68"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "#model.to('cpu')\n",
        "model.eval()\n",
        "get_test_accuracy(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "def draw_confussion_matrix(model,data_loader):\n",
        "  model.eval()\n",
        "  predict=[]\n",
        "  truth=[]\n",
        "  real_predict=[]\n",
        "  real_symbols=[]\n",
        "  for imgs, labels in data_loader:\n",
        "    output = model(Google(imgs))\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    predict.append(pred)\n",
        "    truth.append(labels)\n",
        "  for predict_batch in predict:\n",
        "    for predicts in predict_batch:\n",
        "      real_predict.append(classes[predicts.item()])\n",
        "  for symbol_batch in truth:\n",
        "    for symbol in symbol_batch:\n",
        "      real_symbols.append(classes[symbol.item()])\n",
        "  print(len(real_predict),len(real_symbols))\n",
        "  df_cm = pd.DataFrame(confusion_matrix(real_symbols,real_predict), index = [i for i in classes],\n",
        "                  columns = [i for i in classes])\n",
        "  plt.figure(figsize = (10,7))\n",
        "  sn.heatmap(df_cm, annot=True) #cite:https://seaborn.pydata.org/generated/seaborn.heatmap.html\n"
      ],
      "metadata": {
        "id": "5PWxSvE-Xor1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=5,num_workers=num_workers, shuffle=True)\n",
        "draw_confussion_matrix(model,test_loader)"
      ],
      "metadata": {
        "id": "HtIVOM-OYnYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "602dc6ced75a4686ac7849573a4a8fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa87a47a5cd341118444f2a1380f7676",
              "IPY_MODEL_75d2dd2837c34826abc80572c38cff63",
              "IPY_MODEL_a376ca07094444b3ac578a6253851a86"
            ],
            "layout": "IPY_MODEL_2e659682ce6f4026966b9aee69a64082"
          }
        },
        "aa87a47a5cd341118444f2a1380f7676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e383afb7ccd41f5a4ec73c07c58ea26",
            "placeholder": "​",
            "style": "IPY_MODEL_3a2a11ec50bb4dcc99d7a5cdc282f471",
            "value": "100%"
          }
        },
        "75d2dd2837c34826abc80572c38cff63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e01efbdcedc4479a3df867dcfef78d6",
            "max": 52147035,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc2fe823a44d49058cfac8c29626c818",
            "value": 52147035
          }
        },
        "a376ca07094444b3ac578a6253851a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68f4ee30ac5a424ebfe42f97043ddad6",
            "placeholder": "​",
            "style": "IPY_MODEL_e0589a10729f4288a539140deb9c0011",
            "value": " 49.7M/49.7M [00:00&lt;00:00, 117MB/s]"
          }
        },
        "2e659682ce6f4026966b9aee69a64082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e383afb7ccd41f5a4ec73c07c58ea26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a2a11ec50bb4dcc99d7a5cdc282f471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e01efbdcedc4479a3df867dcfef78d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc2fe823a44d49058cfac8c29626c818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68f4ee30ac5a424ebfe42f97043ddad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0589a10729f4288a539140deb9c0011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
